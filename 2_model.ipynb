{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.embedding_ops import embedding\n",
    "from tflearn.layers.recurrent import bidirectional_rnn, BasicLSTMCell, lstm\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded.\n",
      "859345\n",
      "15262\n",
      "859345\n",
      "15262\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed file and inspect dimensions\n",
    "with open('preprocess_3.pickle', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "    X_val = pickle.load(f)\n",
    "    y_train = pickle.load(f)\n",
    "    y_val = pickle.load(f)   \n",
    "    \n",
    "print(\"File loaded.\")\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(y_train))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 717553, 1: 141792}) 0.165000087276\n",
      "Counter({0: 12744, 1: 2518}) 0.164984929891\n"
     ]
    }
   ],
   "source": [
    "# Check class counts\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(y_train)\n",
    "d = Counter(y_val)\n",
    "\n",
    "c_pct = float(c[1])/(c[0] + c[1])\n",
    "d_pct = float(d[1])/(d[0] + d[1])\n",
    "\n",
    "print(c, c_pct)\n",
    "print(d, d_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\\'preprocess_train\\', \\'rb\\'):  \\n    X_train = joblib.load(\\'preprocess_train\\')\\n\\nprint(\"File loaded.\")\\nprint(len(X_train))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open('preprocess_train', 'rb'):  \n",
    "    X_train = joblib.load('preprocess_train')\n",
    "\n",
    "print(\"File loaded.\")\n",
    "print(len(X_train))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  6  9 10 11 12 13  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  2 31 32 33 21 34 25\n",
      "  35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 36 37 38 39 40  1 36 41 42 40  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2 43 21 44  9 45 46 47 48 49 17 50  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [51 52 53 27 54 51 52 53 55 56 25 57 25 54 58  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Sequence padding\n",
    "#X_train = pad_sequences(X_train, maxlen=235, value=0.)\n",
    "#X_val = pad_sequences(X_val, maxlen=235, value=0.)\n",
    "# Converting labels to binary vectors\n",
    "y_train = to_categorical(y_train, nb_classes=2)\n",
    "y_val = to_categorical(y_val, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9   10   16 1111 1968 1969  633   21 1797    9   10   16 1111 1968 1969\n",
      "  633   21  395    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 40283  | total loss: \u001b[1m\u001b[32m0.12815\u001b[0m\u001b[0m | time: 879.704s\n",
      "| Adam | epoch: 003 | loss: 0.12815 - acc: 0.9542 -- iter: 859328/859345\n",
      "Training Step: 40284  | total loss: \u001b[1m\u001b[32m0.13320\u001b[0m\u001b[0m | time: 882.545s\n",
      "| Adam | epoch: 003 | loss: 0.13320 - acc: 0.9479 | val_loss: 0.38263 - val_acc: 0.8301 -- iter: 859345/859345\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Network building\n",
    "\n",
    "net = input_data(shape=[None, 45])\n",
    "net = embedding(net, input_dim=87514, output_dim=128)\n",
    "net = bidirectional_rnn(net,\n",
    "                        BasicLSTMCell(64), \n",
    "                        BasicLSTMCell(64)\n",
    "                        )\n",
    "net = dropout(net, 0.5)\n",
    "net = fully_connected(net, 2, activation='softmax')\n",
    "net = regression(net, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, \n",
    "                    clip_gradients=0., \n",
    "                    tensorboard_verbose=0, \n",
    "                    checkpoint_path='/home/ubuntu/pynb/quora-question-pairs/checkpoints',\n",
    "                    max_checkpoints=1)\n",
    "\n",
    "#model.load('birnn_1.tflearn')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train, \n",
    "          n_epoch=3,\n",
    "          snapshot_epoch=True,\n",
    "          validation_set=(X_val, y_val),\n",
    "          show_metric=True,\n",
    "          batch_size=64)\n",
    "\n",
    "model.save('birnn_1.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from __future__ import print_function\\nimport numpy as np\\n\\nfrom keras.preprocessing import sequence\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\\n\\nmax_features = 87506\\n# cut texts after this number of words\\n# (among top max_features most common words)\\nmaxlen = 235\\nbatch_size = 32\\n\\nprint(\"Pad sequences (samples x time)\")\\n#X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\\n#X_val = sequence.pad_sequences(X_val, maxlen=maxlen)\\ny_train = np.array(y_train)\\ny_val = np.array(y_val)\\n\\nmodel = Sequential()\\nmodel.add(Embedding(max_features, 128, input_length=maxlen))\\nmodel.add(Bidirectional(LSTM(64)))\\nmodel.add(Dropout(0.5))\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\n\\n# try using different optimizers and different optimizer configs\\nmodel.compile(\\'adam\\', \\'binary_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\nprint(\\'Train...\\')\\nmodel.fit(X_train, y_train,\\n          batch_size=batch_size,\\n          validation_data=[X_val, y_val])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "\n",
    "max_features = 87506\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 235\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "#X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "#X_val = sequence.pad_sequences(X_val, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=[X_val, y_val])'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
